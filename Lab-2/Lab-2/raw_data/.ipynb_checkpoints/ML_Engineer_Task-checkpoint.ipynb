{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af889e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe4e81e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sale_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>P101</td>\n",
       "      <td>C_001</td>\n",
       "      <td>$150.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>P102</td>\n",
       "      <td>C_002</td>\n",
       "      <td>$75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01/20/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>P103</td>\n",
       "      <td>C_001</td>\n",
       "      <td>$250.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>P101</td>\n",
       "      <td>C_003</td>\n",
       "      <td>$150.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01/02/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>P104</td>\n",
       "      <td>C_004</td>\n",
       "      <td>$30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/02/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1996</td>\n",
       "      <td>P104</td>\n",
       "      <td>C_042</td>\n",
       "      <td>$250.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>03/29/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1997</td>\n",
       "      <td>P105</td>\n",
       "      <td>C_014</td>\n",
       "      <td>$30.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03/02/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1998</td>\n",
       "      <td>P104</td>\n",
       "      <td>C_092</td>\n",
       "      <td>$75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/03/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1999</td>\n",
       "      <td>P103</td>\n",
       "      <td>C_063</td>\n",
       "      <td>$250.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10/03/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000</td>\n",
       "      <td>P103</td>\n",
       "      <td>C_042</td>\n",
       "      <td>$250.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21/02/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sale_id product_id customer_id sale_price  quantity   sale_date\n",
       "0       1001       P101       C_001    $150.00       2.0  15/01/2023\n",
       "1       1002       P102       C_002        $75       3.0  01/20/2023\n",
       "2       1003       P103       C_001    $250.50       1.0  25/01/2023\n",
       "3       1004       P101       C_003    $150.00       4.0  01/02/2023\n",
       "4       1005       P104       C_004     $30.00       NaN  05/02/2023\n",
       "..       ...        ...         ...        ...       ...         ...\n",
       "995     1996       P104       C_042    $250.50       4.0  03/29/2023\n",
       "996     1997       P105       C_014     $30.00       1.0  03/02/2023\n",
       "997     1998       P104       C_092        $75       NaN  31/03/2023\n",
       "998     1999       P103       C_063    $250.50       5.0  10/03/2023\n",
       "999     2000       P103       C_042    $250.50       1.0  21/02/2023\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sale_price.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af2cfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing quantity with 1 (default)\n",
    "df['quantity'] = df['quantity'].fillna(1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d574b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_price'] = df['sale_price'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e418817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize date format\n",
    "df['sale_date'] = pd.to_datetime(df['sale_date'], format='mixed', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636b140",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de970ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total purchase amount per transaction\n",
    "df['total_revenue'] = df['sale_price'] * df['quantity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be879c8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "customer_metrics = df.groupby('customer_id').agg(\n",
    "    total_purchase_amount=('total_revenue', 'sum'),\n",
    "    purchase_frequency=('sale_id', 'count'),\n",
    "    avg_transaction_value=('total_revenue', 'mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ae799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b56d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(\n",
    "    customer_metrics[['total_purchase_amount', 'purchase_frequency', 'avg_transaction_value']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89b6c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  fill with defaults if you want to keep them\n",
    "customer_metrics = customer_metrics.fillna(0)\n",
    "\n",
    "# 2. Normalize again after removing/filling NaNs\n",
    "scaled_features = scaler.fit_transform(\n",
    "    customer_metrics[['total_purchase_amount', 'purchase_frequency', 'avg_transaction_value']]\n",
    ")\n",
    "\n",
    "# 3. Now apply K-Means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "customer_metrics['cluster'] = kmeans.fit_predict(scaled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96c55aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_id            0\n",
       "product_id         0\n",
       "customer_id        0\n",
       "sale_price       200\n",
       "quantity           0\n",
       "sale_date          0\n",
       "total_revenue    200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a375c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "customer_metrics['cluster'] = kmeans.fit_predict(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "253220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identify VIP cluster (highest spending)\n",
    "vip_cluster = customer_metrics.groupby('cluster')['total_purchase_amount'].mean().idxmax()\n",
    "customer_metrics['VIP_status'] = np.where(\n",
    "    customer_metrics['cluster'] == vip_cluster, 'VIP', 'Non-VIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cb9674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VIP classification complete. File saved as 'sales_data_with_VIP.csv'.\n",
      "   sale_id product_id customer_id  sale_price  quantity  sale_date  \\\n",
      "0     1001       P101       C_001       150.0         2 2023-01-15   \n",
      "1     1002       P102       C_002        75.0         3 2023-01-20   \n",
      "2     1003       P103       C_001       250.5         1 2023-01-25   \n",
      "3     1004       P101       C_003       150.0         4 2023-01-02   \n",
      "4     1005       P104       C_004        30.0         1 2023-05-02   \n",
      "\n",
      "   total_revenue VIP_status_x VIP_status_y  \n",
      "0          300.0      Non-VIP      Non-VIP  \n",
      "1          225.0      Non-VIP      Non-VIP  \n",
      "2          250.5      Non-VIP      Non-VIP  \n",
      "3          600.0      Non-VIP      Non-VIP  \n",
      "4           30.0      Non-VIP      Non-VIP  \n"
     ]
    }
   ],
   "source": [
    "# 5. Merge VIP status back into main dataset (Reverse ETL)\n",
    "df = df.merge(customer_metrics[['customer_id', 'VIP_status']], on='customer_id', how='left')\n",
    "\n",
    "# 6. Export enriched dataset\n",
    "file_path=\"data_warehouse/sales_data_with_VIP.csv\"\n",
    "df.to_csv(file_path, index=False)\n",
    "print(\"âœ… VIP classification complete. File saved as 'sales_data_with_VIP.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef9a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
